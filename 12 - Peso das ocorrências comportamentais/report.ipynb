{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Convertendo 1 - Data Loading.ipynb ‚Üí 1 - Data Loading.pdf\n",
      "\n",
      "üîÑ Convertendo 2 - Data Analysis.ipynb ‚Üí 2 - Data Analysis.pdf\n",
      "\n",
      "üîÑ Convertendo report.ipynb ‚Üí report.pdf\n",
      "\n",
      "‚úÖ Convers√£o de todos os notebooks finalizada.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import getpass\n",
    "from pathlib import Path\n",
    "\n",
    "# --- CONFIGURA√á√ÉO ---\n",
    "raw_source = \"./\"\n",
    "# Se o path come√ßar com \"/media~/\", substitui \"~\" pelo seu usu√°rio em /media\n",
    "username = getpass.getuser()\n",
    "if raw_source.startswith(\"/media/~/\"):\n",
    "    corrected = raw_source.replace(\"/media/~/\", f\"/media/{username}/\")\n",
    "else:\n",
    "    corrected = raw_source\n",
    "# Agora expande \"~\" se ainda existir\n",
    "SOURCE_DIR = Path(os.path.expanduser(corrected))\n",
    "OUTPUT_DIR = SOURCE_DIR / \"pdfs\"\n",
    "PYTHON_EXE = sys.executable\n",
    "# ---------------------\n",
    "\n",
    "# Verifica pasta de origem\n",
    "if not SOURCE_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Pasta de origem n√£o encontrada: {SOURCE_DIR}\")\n",
    "\n",
    "# Cria apenas a pasta pdfs dentro de SOURCE_DIR, sem recriar o resto\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Converte cada .ipynb em PDF\n",
    "for nb_path in SOURCE_DIR.glob(\"*.ipynb\"):\n",
    "    pdf_name = nb_path.stem + \".pdf\"\n",
    "    cmd = [\n",
    "        PYTHON_EXE, \"-m\", \"jupyter\", \"nbconvert\",\n",
    "        str(nb_path),\n",
    "        \"--to\", \"pdf\",\n",
    "        \"--output\", pdf_name,\n",
    "        \"--output-dir\", str(OUTPUT_DIR),\n",
    "        \"--debug\"\n",
    "    ]\n",
    "    print(f\"üîÑ Convertendo {nb_path.name} ‚Üí {pdf_name}\")\n",
    "    try:\n",
    "        out = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
    "        print(out.stdout)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"‚ùå Erro ao converter {nb_path.name}:\\n{e.stderr}\")\n",
    "print(\"‚úÖ Convers√£o de todos os notebooks finalizada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisando os documentos escreva uma apresenta√ß√£o detalhada do estudo, em alto n√≠vel.\n",
    "# Escrever 15 par√°grafo\n",
    "# N√£o incluir nada de python\n",
    "# Explicar em alto nivel\n",
    "# Um leigo deve entender do que se trata\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Analisando os documentos descreva a metodologia e os resultados que foram obtidos no estudo.\n",
    "# Escrever 15 par√°grafo\n",
    "# N√£o incluir nada de python\n",
    "# Explicar em alto nivel\n",
    "# Um leigo deve entender do que se trata\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Analisando os documentos descreva a analise e discuss√£o e os resultados que foram obtidos no estudo.\n",
    "# Escrever 15 par√°grafo\n",
    "# N√£o incluir nada de python\n",
    "# Explicar em alto nivel\n",
    "# Um leigo deve entender do que se trata\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Analisando os documentos descreva as conclus√µes do estudo\n",
    "# Escrever 15 par√°grafo\n",
    "# N√£o incluir nada de python\n",
    "# Explicar em alto nivel\n",
    "# Um leigo deve entender do que se trata\n",
    "\n",
    "\n",
    "# Agora com base nos texto gerado nas etapas anteriores quero um relat√≥rio completo.\n",
    "# Este relat√≥rio deve comunicar os achados para os tomadores de decis√£o\n",
    "# N√£o incluir nada de python\n",
    "# Explicar em alto nivel\n",
    "# Um leigo deve entender do que se trata\n",
    "# Estrutura do relat√≥rio: Apresenta√ß√£o (4 paragrafos), metodologia e resultados(8 paragrafos), an√°lise e discuss√£o(4 paragrafos), conclus√£o(2 paragrafos)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisando os documentos extraia os codigos que geram visualiza√ß√µes.\n",
    "# Adapte estes codigos para salvar as imagens em PNG na pasta \"figuras\"\n",
    "# Nomear estas Figuras em ordem, figura_1.png, figura_2.png, figura_3.png, et\n",
    "# Retornar um codigo unico que gere e salve todas as imangens em png na pasta correta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash num√©rica de 5 d√≠gitos: 94799\n"
     ]
    }
   ],
   "source": [
    "from src.libs.lib import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_original = pd.read_csv(\"src/data/tabela_ocorrencias_dbpx_com_a_pontua√ß√£o_academia.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogramas ‚Üí figuras/figura_1.png\n",
      "Boxplot Pontua√ß√£o por Ocorr√™ncia ‚Üí figuras/figura_2.png\n",
      "Frequ√™ncia de Ocorr√™ncias ‚Üí figuras/figura_3.png\n",
      "Distribui√ß√£o por Quartil ‚Üí figuras/figura_4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_216134/2523262898.py:86: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  df.set_index('occurence_create').resample('M')['Pontua√ß√£o Atualiza√ß√£o'].mean().plot(figsize=(12, 5))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M√©dia por M√™s ‚Üí figuras/figura_5.png\n",
      "Heatmap de Correla√ß√£o ‚Üí figuras/figura_6.png\n",
      "Dispers√£o Pontua√ß√£o ‚Üí figuras/figura_7.png\n",
      "Conting√™ncia Descri√ß√£o x Observa√ß√£o ‚Üí figuras/figura_8.png\n",
      "Top Motoristas ‚Üí figuras/figura_9.png\n",
      "Cascata de Impacto ‚Üí figuras/figura_10.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Preparar o DataFrame\n",
    "df = df_original.copy()\n",
    "\n",
    "# Convers√µes necess√°rias\n",
    "df['Pontua√ß√£o'] = pd.to_numeric(df['Pontua√ß√£o'], errors='coerce')\n",
    "df['Pontua√ß√£o Atualiza√ß√£o'] = pd.to_numeric(df['Pontua√ß√£o Atualiza√ß√£o'], errors='coerce')\n",
    "df['Pontua√ß√£o Comit√™'] = pd.to_numeric(df['Pontua√ß√£o Comit√™'], errors='coerce')\n",
    "df['occurence_create'] = pd.to_datetime(df['occurence_create'], errors='coerce')\n",
    "\n",
    "# Quartis da Pontua√ß√£o Atualiza√ß√£o\n",
    "try:\n",
    "    pontuacoes_validas = df['Pontua√ß√£o Atualiza√ß√£o'].dropna()\n",
    "    bin_edges = pd.qcut(pontuacoes_validas, q=4, retbins=True, duplicates='drop')[1]\n",
    "    label_count = len(bin_edges) - 1\n",
    "    labels = [f\"Q{i+1}\" for i in range(label_count)]\n",
    "    df['pontuacao_quartil'] = pd.qcut(df['Pontua√ß√£o Atualiza√ß√£o'], q=label_count, labels=labels, duplicates='drop')\n",
    "except Exception as e:\n",
    "    print(\"Erro ao criar quartis de pontua√ß√£o:\", e)\n",
    "    df['pontuacao_quartil'] = None\n",
    "\n",
    "# Quartis da coluna observation (se poss√≠vel)\n",
    "try:\n",
    "    obs_numeric = pd.to_numeric(df['observation'], errors='coerce')\n",
    "    df['observation_quartil'] = pd.qcut(obs_numeric, q=4, duplicates='drop')\n",
    "except:\n",
    "    df['observation_quartil'] = None\n",
    "\n",
    "# Criar a pasta 'figuras' se necess√°rio\n",
    "os.makedirs(\"figuras\", exist_ok=True)\n",
    "\n",
    "# Fun√ß√£o para gerar e salvar gr√°ficos sequencialmente\n",
    "def gerar_graficos_e_salvar(df):\n",
    "    figura_id = 1\n",
    "\n",
    "    def salvar_fig(titulo):\n",
    "        nonlocal figura_id\n",
    "        filename = f\"figuras/figura_{figura_id}.png\"\n",
    "        plt.savefig(filename, bbox_inches='tight')\n",
    "        print(f\"{titulo} ‚Üí {filename}\")\n",
    "        figura_id += 1\n",
    "        plt.close()\n",
    "\n",
    "    # Histograma\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(df['Pontua√ß√£o Atualiza√ß√£o'].dropna(), kde=True, color='blue', bins=30)\n",
    "    plt.title('Histograma - Pontua√ß√£o Atualiza√ß√£o')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(df['Pontua√ß√£o Comit√™'].dropna(), kde=True, color='green', bins=30)\n",
    "    plt.title('Histograma - Pontua√ß√£o Comit√™')\n",
    "    salvar_fig(\"Histogramas\")\n",
    "\n",
    "    # Boxplot\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.boxplot(data=df, x='Pontua√ß√£o Atualiza√ß√£o', y='description')\n",
    "    plt.title('Boxplot - Pontua√ß√£o Atualiza√ß√£o por Tipo de Ocorr√™ncia')\n",
    "    salvar_fig(\"Boxplot Pontua√ß√£o por Ocorr√™ncia\")\n",
    "\n",
    "    # Frequ√™ncia\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    df['description'].value_counts().head(20).plot(kind='bar')\n",
    "    plt.title('Frequ√™ncia das Ocorr√™ncias (Top 20)')\n",
    "    plt.xlabel('Descri√ß√£o')\n",
    "    plt.ylabel('Frequ√™ncia')\n",
    "    plt.xticks(rotation=75)\n",
    "    salvar_fig(\"Frequ√™ncia de Ocorr√™ncias\")\n",
    "\n",
    "    # Barras empilhadas\n",
    "    if df['pontuacao_quartil'].notna().any():\n",
    "        top10_desc = df['description'].value_counts().head(10).index\n",
    "        temp = df[df['description'].isin(top10_desc)]\n",
    "        crosstab = pd.crosstab(temp['description'], temp['pontuacao_quartil'], normalize='index')\n",
    "        crosstab.plot(kind='bar', stacked=True, figsize=(12, 6), colormap='viridis')\n",
    "        plt.title('Distribui√ß√£o por Quartil nas Top 10 Ocorr√™ncias')\n",
    "        plt.ylabel('Propor√ß√£o')\n",
    "        salvar_fig(\"Distribui√ß√£o por Quartil\")\n",
    "\n",
    "    # Linha temporal\n",
    "    df.set_index('occurence_create').resample('M')['Pontua√ß√£o Atualiza√ß√£o'].mean().plot(figsize=(12, 5))\n",
    "    plt.title('M√©dia da Pontua√ß√£o Atualiza√ß√£o por M√™s')\n",
    "    plt.ylabel('M√©dia')\n",
    "    plt.xlabel('Data')\n",
    "    salvar_fig(\"M√©dia por M√™s\")\n",
    "\n",
    "    # Heatmap correla√ß√£o\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(df[['Pontua√ß√£o', 'Pontua√ß√£o Atualiza√ß√£o', 'Pontua√ß√£o Comit√™']].corr(), annot=True, cmap='coolwarm')\n",
    "    plt.title('Correla√ß√£o entre as Pontua√ß√µes')\n",
    "    salvar_fig(\"Heatmap de Correla√ß√£o\")\n",
    "\n",
    "    # Dispers√£o\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x='Pontua√ß√£o Atualiza√ß√£o', y='Pontua√ß√£o Comit√™', data=df)\n",
    "    plt.title('Dispers√£o: Atualiza√ß√£o vs Comit√™')\n",
    "    salvar_fig(\"Dispers√£o Pontua√ß√£o\")\n",
    "\n",
    "    # Heatmap de conting√™ncia\n",
    "    if df['observation_quartil'].notna().any():\n",
    "        cont_table = pd.crosstab(df['description'], df['observation_quartil'])\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        sns.heatmap(cont_table, annot=False, cmap='Blues')\n",
    "        plt.title('Heatmap: Descri√ß√£o √ó Quartil de Observa√ß√£o')\n",
    "        salvar_fig(\"Conting√™ncia Descri√ß√£o x Observa√ß√£o\")\n",
    "\n",
    "    # Top 20 motoristas\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    df['driver_id'].value_counts().head(20).plot(kind='bar')\n",
    "    plt.title('Top 20 Motoristas com Mais Ocorr√™ncias')\n",
    "    plt.xlabel('driver_id')\n",
    "    plt.ylabel('Ocorr√™ncias')\n",
    "    salvar_fig(\"Top Motoristas\")\n",
    "\n",
    "    # Cascata de impacto\n",
    "    impacto = df.groupby('description')['Pontua√ß√£o Atualiza√ß√£o'].sum().sort_values(ascending=False).head(15)\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.bar(impacto.index, impacto.values)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title('Impacto Total da Pontua√ß√£o Atualiza√ß√£o por Evento')\n",
    "    salvar_fig(\"Cascata de Impacto\")\n",
    "\n",
    "# Rodar\n",
    "gerar_graficos_e_salvar(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisando o relat√≥rio gerado na etapa anterior quero que gere um c√≥digo python para gerar um fluxograma\n",
    "# Incluir neste fluxograma as etapas do estudo\n",
    "# Incluir os principais resultados\n",
    "# Incluir os principais achados\n",
    "# Incluir as principais conclus√µes\n",
    "# O fluxograma deve ser salvo na pasta \"figuras\" como um arquivo png\n",
    "# O nome do arquivo deve ser \"fluxograma.png\"\n",
    "# O c√≥digo deve ser √∫nico e gerar o fluxograma completo\n",
    "# O c√≥digo deve ser execut√°vel e gerar o fluxograma completo\n",
    "# C√≥digo de referencia: from graphviz import Digraph# Fluxograma acad√™mico estilizadoflow = Digraph('Academic_Flowchart', format='png')# Atributos do grafo (layout)flow.attr('graph',           rankdir='TB',           # Dire√ß√£o top-to-bottom para estilo acad√™mico          fontsize='12',           fontname='Times New Roman',          bgcolor='white',           margin='0.2')# Atributos dos n√≥s (estilo acad√™mico)flow.attr('node',           shape='rectangle',           style='rounded,filled',           fillcolor='#F7F9FB',    # Tom suave          color='#2E4053',        # Borda escura          fontname='Times New Roman',           fontsize='12',           margin='0.2')# Atributos das arestas (linhas)flow.attr('edge',           color='#2E4053',           arrowhead='vee',           penwidth='1.5')# Defini√ß√£o das etapasetapas = [    ('A', 'In√≠cio'),    ('B', '1. Importa√ß√£o de Dados\\n(pandas)'),    ('C', '2. Pr√©-processamento\\n(numpy, unidecode)'),    ('D', '3. Estat√≠stica Descritiva\\n(statsmodels)'),    ('E', '4. Modelagem Preditiva\\n(scikit-learn)'),    ('F', '5. Visualiza√ß√£o de Dados\\n(matplotlib, seaborn)'),    ('G', '6. Exporta√ß√£o de Relat√≥rios\\n(openpyxl, tabulate)'),    ('H', '7. Deploy & BQ\\n(functions-framework,\\ngoogle-cloud-bigquery)'),    ('I', 'Conclus√£o')]# Cria os n√≥sfor key, label in etapas:    flow.node(key, label)# Conecta as etapas em sequ√™nciafor (src, _), (dst, _) in zip(etapas, etapas[1:]):    flow.edge(src, dst)# Exibe o fluxogramaflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'figuras/fluxograma.png'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "import os\n",
    "\n",
    "# Criar pasta se necess√°rio\n",
    "os.makedirs(\"figuras\", exist_ok=True)\n",
    "\n",
    "# Criar fluxograma\n",
    "fluxograma = Digraph('Fluxograma_Estudio', format='png')\n",
    "\n",
    "# Configura√ß√µes de layout e estilo\n",
    "fluxograma.attr('graph', rankdir='TB', fontsize='12', fontname='Times New Roman', bgcolor='white', margin='0.2')\n",
    "fluxograma.attr('node', shape='rectangle', style='rounded,filled', fillcolor='#F7F9FB',\n",
    "                color='#2E4053', fontname='Times New Roman', fontsize='12', margin='0.2')\n",
    "fluxograma.attr('edge', color='#2E4053', arrowhead='vee', penwidth='1.5')\n",
    "\n",
    "# Defini√ß√£o das etapas do estudo\n",
    "etapas = [\n",
    "    ('A', 'In√≠cio do Estudo'),\n",
    "    ('B', '1. Coleta de Dados\\n67.554 registros analisados'),\n",
    "    ('C', '2. Organiza√ß√£o dos Dados\\nTipos de eventos e pontua√ß√µes'),\n",
    "    ('D', '3. An√°lise Explorat√≥ria\\nFrequ√™ncia, boxplots, dispers√£o, correla√ß√µes'),\n",
    "    ('E', '4. Identifica√ß√£o de Padr√µes\\nExcesso de \"Dia agenciado\", reincid√™ncias'),\n",
    "    ('F', '5. An√°lise Temporal\\nVaria√ß√£o das m√©dias mensais'),\n",
    "    ('G', '6. Revis√µes e Ajustes\\nDiferen√ßas entre sistema e comit√™'),\n",
    "    ('H', '7. Resultados-Chave\\n- 95% \"Dia agenciado\"\\n- Inconsist√™ncias em revis√µes\\n- Perfis reincidentes'),\n",
    "    ('I', '8. Conclus√µes\\nNecessidade de revis√£o de crit√©rios,\\ntratamento da reincid√™ncia e padroniza√ß√£o'),\n",
    "    ('J', 'Fim do Estudo')\n",
    "]\n",
    "\n",
    "# Criar n√≥s\n",
    "for key, label in etapas:\n",
    "    fluxograma.node(key, label)\n",
    "\n",
    "# Criar conex√µes\n",
    "for i in range(len(etapas) - 1):\n",
    "    src, _ = etapas[i]\n",
    "    dst, _ = etapas[i + 1]\n",
    "    fluxograma.edge(src, dst)\n",
    "\n",
    "# Salvar o fluxograma\n",
    "fluxograma.render(filename='fluxograma', directory='figuras', cleanup=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Agora com base no relat√≥rio completo quero que gere um documento HTML para ele. \n",
    "# N√£o usar Python nesta etapa.\n",
    "# Gerar em HTMl puramente.\n",
    "# Usar as normas da ABNT\n",
    "# Neste documento incluir o texto adaptado do relat√≥rio. \n",
    "# Incluir tamb√©m as figuras geradas na etapa anterior. com titulos e descri√ß√£o.\n",
    "# Incluir e citar no texto as figuras a partir dos PNGs gerados na etapa anterior\n",
    "# Tamb√©m incluir o fluxograma gerado na etapa anterior.\n",
    "# Deixar responsivo\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pesos_ocorrencias_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
